Many companies are betting onartificial intelligence’s powerto transform key aspects of teaching and learning.
Pearson, in partnership with a British university, is investing in AI’s potential to more accurately assess a growing population in U.S. districts and other school systems around the world: English-language learners.
Mary Richardsonis the leader for the education (assessment) master’s degree program at University College, London.

Rose Cleshamis the director of academic standards and measurement in Pearson’s global assessment division, and is also a fellow at UCL.


In February, Pearson and University College London launched a three-year project examining how artificial intelligence can promote fairness and uniformity in the scoring of English-language learning assessments.
According to the global education company, the research will focus on test-takers’ end-to-end experience of PTE, Pearson’s high-stakes English test, for study or migration purposes.
Pearson’s computer-based testing arm, Pearson VUE, is administering the fully digital test, which is being led by Mary Richardson, UCL associate professor of education; along with Rose Clesham, Pearson PTE director of academic standards, measurement and research; Bryan Maddox, Microanalytics’ executive director; and, Sandra Leaton-Gray, UCL associate professor of education.
The project will involve feeding test-taker responses—including spokenresponses—into the ongoing development and use of AI for assessment.
The purpose of the test, according to Pearson, is to establish an accurate global standard for scoring English language assessments, accounting for subtle variations in vocabulary and sentence structure that can surface between derivations of English from different countries.
EdWeek Market Briefcontributing writer Brian Bradley asked Richardson and Clesham about what the project could mean for AI’s potential worldwide applications to English language assessments.
How did the idea for this project originate?
Richardson:There’s very, very little out there in the research literature, particularly on the test-takers’ experiences of AI technologies and taking these particular tests in these particular situations. That’s something that we’re very interested in. A lot of my work is about ethics and trust in assessment, so we’re really interested in looking at and documenting the experiences of test-takers, so Pearson can then also use that to feed back into developments going forward, because this is part of the future of assessment. What we want is really fair and good-quality research that guides practice in and out of industry.
What makes the technology associated with this project AI?
Clesham:AI is a generic term. Some people would say AI, from its first principle, started with the Enigma machines during the Second World War, where you would get computers to run large amounts of data instead of having to do it by human hand. Some people would actually say it started in the space race, where IBM computers started to work out landing profiles more quickly and more accurately than humans could. The recent jumping point came just under 10 years ago with the advancement of machine learning, which uses and links information to predict what’s going to happen in a new response.
Could you describe Pearson’s test of English-language learners, PTE Academic?
Clesham:It is a completely computerized machine-scored test of language proficiency, which is operated globally, for summative purposes, for high-stakes tests. But that same technology is also used for formative and diagnostic purposes. We set out to develop a proficiency test that didn’t omit any of the four language skills of speaking, writing, listening, and reading.
For speaking and writing, every person’s response is going to be individual and personal to them. It’s in those schools that we use our machine learning or artificial intelligence to mark and grade them.
How does this particular application of AI work?
Clesham:What we essentially do is we train our engines and we train our AI systems on up to 500-1,000 individual responses that are taken from a representative sample of different locations, different accents. So we train every single item using representative responses from all over the world.
Once we have trained the engine on that response, we go and validate it. The responses are human-scored. So we train the engine using the responses and the human scores that have been marked at least twice. To mark a new response, we then feed in at least 500-1,000 new responses, which also have been human-marked, and for them, we can check to see whether the reliability of the machine’s marks match the expert human marks.
How would this approach create more accurate and uniform scoring that human scoring?
Clesham:It is very difficult to keep thousands of people to exactly the same standard. These technologies use a very small number of expert human raters, maybe 12 raters who are taken from representative areas and are top experts in the field. They effectively establish the standard, and their response trains the engine, so there’s no drift of standards. Effectively, that’s the same system that we use for the speaking and writing items. They’re trained on human expert-marked responses. Those marks are validated, and then what happens, basically, is in these AI systems, the system predicts a score on a new response that it hasn’t seen before.
Periodically, we will check that those ratings are still the same as a human would give them, and we also carry out differential item functions. So we look at the global data and check that there’s no bias occurring by group or gender. And we can check that because all our data is available, and analyzed, by us.
Several reports in recent years have claimed potential racial or gender biases are inherent in AI technology. How would the project address any bias alleged by test-takers?
Clesham:If there is an issue and somebody says, “We think that we have been disadvantaged,” we can then run through the data. Further, if somebody thinks that their response has been unfairly treated, then we can check that response, and double-check that that is not the case. So in very rare cases, if an item has been marked by the machine and somebody has a valid reason for thinking that they were disadvantaged in some way, then we can send it over to an expert human rater who can double-check the marks.
Why is it important to have one global standard for scoring English language tests?
Clesham:Language testing, in particular, has a very clear global currency. We are living in a position now where we know that people are moving globally for study purposes. They’re moving globally for work purposes, for professional purposes, for migration purposes. And for many of these areas, they actually need to achieve particular scores on language proficiency tests to gain entry into any of those sectors from university to professional bodies to migration purposes. What it was set up to do was to avoid the issue of someone saying, “I applied, and I took my course in Hong Kong, and I was assessed by somebody who didn’t like me very much, and I think I was disadvantaged.”

This just takes that out of the equation completely. So international language testing has a very clearly defined currency in terms of global movement. And so we feel that it’s very important that we then create a level playing field for anybody wherever they’re going to test or whomever they are.
What are the practical applications for English-language learning in this technology?
Clesham:The technology itself and the underpinning technology are used in formative and classroom-based education, and partly in response to the notion of teacher time, so that if people want to practice outside the classroom, they can get almost immediate feedback on reading and writing and speaking for practice. So it gives them immediate feedback for improvement purposes. As we know, a student will only get better if they practice. Any footballer will tell you that. And the limiting factor for informed practice is teacher time. So these technologies are seen as potentially a really positive way forward.
Richardson:It’s actually understanding that feedback can go in and can keep going back in. And one of the things we know from assessment research is that the speed at which a child or an adult, for that matter, gets good quality feedback is absolutely critical in how their learning can progress. So it’s a fundamental thing that we find again and again in good learning models.
What do you mean by “good quality feedback?”
Richardson:The kind of information that will actually help you plan to move on. So, not just a grade of, “OK, you just have failed that,” but actually understanding where it was that we had a problem, being able to identify quite clearly which part of that test I had problems with, which part didn’t I do so well in, so I can find out how I can actually realign my learning goals and what I already know, so I can have another go?
Clesham:One of the problems that teachers have in terms of assessment on a day-to-day basis is that if you are assessing writing, for example, then there are maybe multiple skills within that writing that you can rate and mark individually. There might be three to five traits that are going on at the same time, and that takes an enormous amount of time to go over all that and give feedback to students. One of the advantages that we can benefit from in terms of machine learning is that once those engines are trained on multiple traits, then these machines can churn out the work effortlessly.
Will these technologies eventually replace teachers?
Clesham:What we say very strongly is that these are not replacing teachers. These are actually designed to help teachers. You will never replace the rich sort of relationship that a teacher can have with a student. But what these systems can do is take a lot of legwork on, in terms of the actual marking and writing, so that the teachers can actually acquire their skills and then have more time to do it.
What K-12 applications of this technology have there been?
Clesham:Parts of them have been used in the PARCC [Partnership for Assessment of Readiness for College and Careers] assessments for readiness for college. We have a number of learning products that use machine learning to give students feedback in and outside of the classroom.
What are some of the biggest barriers to scoring assessments for English-language learners?
Clesham:If you think about human scoring, then this is an extremely well-known and -researched area. We know that there are consistency issues between scorers. In other words, one rater will always have a slightly different notion or standard than somebody else. Even the raters themselves have reliability issues, because you’re required to apply some slightly different sets of standards from a Monday to a Friday.
What is critical for this phase of the project?
Clesham:At this phase, it’s about raising public awareness and understanding, which feed how these systems operate in an educational space. This human aspect is absolutely crucial for these technologies to go forward and to validate what it’s like to be an actual test-taker in these environments. And because people are taking these tests for professional movements, for migration movements, we want to be involved in raising public awareness of what the technology’s about, and about the experiences of different types of test-takers.
What potential pitfalls do you see in this work?
Richardson:We look into domains outside of education to see what we can learn from those and see how it applies in educational contexts. But I think the important thing to remember with that question—I would always turn that around and say: Is there an expectation that human beings assess in a highly reliable way?
They’re not that reliable versus other assessors. There’s intrinsic error within the design of most high-tech tasks. There is the capacity to make human errors and mistakes. That happens anywhere in the world. One of the things we have to be cognizant of is what evidence there is, and generally, the evidence is that AI, in its current context, is very reliable.
Should assessors be worried about AI taking their jobs?
Richardson:No. This is the problem of people’s fear of the colloquial “rise of machines,” which is quite amazing. Machines are only as good as the algorithms that we program into them, and we have to test and re-test, and we check and re-check things, because we know that human beings are flawed in how they assess and approach bias and unfairness. Also, this is only one bit of global testing and assessment.
But some of the testing that teachers and other educators are involved in, quite frankly, is quite dull, repetitive stuff that could be better moved to machines in a reliable and accepted way. And then, we can spend a lot more time doing things where we really are looking at learning, what it is that children or students are learning. So from an academic point of view, I’m really keen when we can find technologies that help us as educators to have more time to spend with our students on tasks that aren’t a summative task. That’s a really positive thing.
FollowEdWeek Market Briefon Twitter@EdMarketBriefor connect with us onLinkedIn.

See also: